#!/usr/bin/env python


def get_args():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--run', required=True)
    parser.add_argument('--config', required=True)
    parser.add_argument('-n', '--max-workers', type=int, default=300)

    parser.add_argument('--nocancel', action='store_true')

    parser.add_argument('--chunksize', type=int, default=1)

    parser.add_argument('--limit', type=int)

    parser.add_argument('--nowarp', action='store_true')

    return parser.parse_args()


def main():
    import numpy as np
    import fitsio
    import esutil as eu
    from pprint import pprint
    from tqdm import tqdm as progress
    from mdet_lsst_sim.doshear import (
        jackknife, read_config, get_flist, print_stats,
        get_mc_file,
    )
    from mattspy.condor_exec import BNLCondorExecutor
    from concurrent.futures import as_completed
    # from concurrent.futures import TimeoutError

    args = get_args()

    config = read_config(args.config)

    flist = get_flist(args.run, limit=args.limit)
    flist.sort()

    # jackknife chunksize
    jack_chunksize = args.chunksize

    worker_chunks = np.array_split(flist, args.max_workers)

    worker_inputs = [
        (config, jack_chunksize, worker_chunk)
        for worker_chunk in worker_chunks
    ]

    print('run:', args.run)
    print('processing:', len(flist))
    print('jackknife chunksize:', jack_chunksize)
    pprint(config)

    # defaults to mem=2
    with BNLCondorExecutor(max_workers=args.max_workers) as cexec:

        futures = [
            cexec.submit(do_work, worker_input)
            for worker_input in worker_inputs
        ]

        nf = len(futures)
        dlist = []
        for future in progress(as_completed(futures), total=nf):
            dlist += future.result()

    print('processed:', len(flist))

    data = {}

    for data_dict in dlist:
        for key in data_dict:
            if key not in data:
                data[key] = []
            data[key].append(data_dict[key])

    for key in data:
        print('jackknifing:', key)
        key_data = eu.numpy_util.combine_arrlist(data[key])

        st = jackknife(key_data, nocancel=args.nocancel)
        print_stats(st)

        fname = get_mc_file(
            run=args.run,
            key=key,
            nocancel=args.nocancel,
            require_primary=config['require_primary'],
        )

        print('writing:', fname)
        fitsio.write(fname, st, clobber=True)


def do_work(inputs):
    from mdet_lsst_sim.doshear import process_set

    config, jack_chunksize, worker_flist = inputs

    nf = len(worker_flist)

    jack_chunked_inputs = [
        (config, worker_flist[start:start+jack_chunksize])
        for start in range(0, nf, jack_chunksize)
    ]

    # list of dicts
    return [
        process_set(inputs) for inputs in jack_chunked_inputs
    ]


if __name__ == '__main__':
    main()
